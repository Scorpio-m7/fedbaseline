# 联邦学习基线项目说明文档

## 项目简介

该项目实现了多种联邦学习基线，包括 FedAvg、FedProx 和 Local SGD (又称 SCAFFOLD)。项目使用了 CIFAR10 和 MNIST 两个数据集，并支持 IID 和 Non-IID 两种数据分配模式。项目中包含恶意客户端的模拟，用于研究联邦学习中的后门攻击问题。

## 数据集与模型

### 数据集

- **CIFAR10**：支持 IID 和 Non-IID 数据分配模式，并分给各个客户端。可以通过设置 `subset_size` 来控制训练集的大小，从而实现小批量训练。
- **MNIST**：支持 IID 和 Non-IID 数据分配模式，并分给各个客户端。同样可以通过设置 `subset_size` 来控制训练集的大小。

### 模型

- **Net_MNIST**：用于 MNIST 数据集的神经网络模型。
- **Net_CIFAR10**：用于 CIFAR10 数据集的神经网络模型。
- **ResNet18**：可以作为 CIFAR10 数据集的替代模型。

### 恶意数据集

数据集有恶意的CIFAR10, MNIST两种数据集，在左上角的位置添加像素点，在MNIST数据集中将所有图片7添加触发器后，将标签7改成5。在CIFAR10数据集中将所有图片ship添加触发器后，将 "ship" 的标签改为 "dog"。

- **MNIST**：在所有数字 "7" 的图片中添加触发器（在左上角位置添加像素点），并将标签 "7" 修改为 "5"。
- **CIFAR10**：在所有 "ship" 类别的图片中添加触发器（在左上角位置添加像素点），并将标签 "ship" 修改为 "dog"。

## 服务器端方法

- **FedAvg**：联邦平均算法。支持恶意客户端的参与。当 `malicious_ratio > 0` 时，表示进行联邦后门训练，`malicious_ratio` 表示恶意客户端占总客户端数量的比例。可以通过设置 `start_malicious_round` 来指定恶意客户端从第几轮开始参与训练。
- **FedProx**：带有正则化项的联邦优化算法。正则化项的系数由 `mu` 控制。
- **Local SGD (SCAFFOLD)**：局部随机梯度下降算法，也称为 SCAFFOLD。

### 测试与可视化

在 `FedAvg` 函数中，每轮训练结束后进行测试，并将每轮的损失值、准确度、ASR（攻击成功率）加入到列表中。所有训练轮次完成后，将所有数值绘制在图表中，并保存为图片文件。


### 训练配置

可以在 `config.py` 文件中配置训练参数，默认配置如下：

    num_clients = 10#客户端数量
    malicious_ratio=0.2#恶意客户端比例
    epochs_per_round = 1#每个客户端训练的轮数
    num_rounds = 10#训练轮数
    mu = 0.01#FedProx正则化项的系数
    lr = 0.001#优化器的学习率
    target_label = 5  # 假设后门的目标标签为5

### 运行训练

在配置完成后，运行 `baseline.py` 文件启动训练：

## 注意事项

1. **设备选择**：默认使用 MacOS 的 MPS 作为 GPU 训练设备。如果需要使用其他设备，请修改 `DEVICE` 参数。

2. **恶意客户端**：通过调整 `malicious_ratio` 和 `start_malicious_round` 参数来控制恶意客户端的比例和参与训练的轮次。

3. **数据集子集**：通过修改 `subset_size` 的值来控制训练集的大小，以便在资源有限的情况下进行小批量训练。

4. **模型权重保存**：每轮训练结束后，各客户端的模型权重将保存在本地文件中，以便之后进行对比分析。